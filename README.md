# Self-Correcting AI Framework

## Overview
The **Self-Correcting AI Framework** is an open-source AI system designed to ensure logical consistency, detect deception, self-correct over time, and apply ethical decision-making based on **entropy analysis and Hermetic principles.**

This system **prevents ideological manipulation, propaganda-based misinformation, and logical inconsistencies** by applying a **dynamic, probability-driven, and ethically grounded decision process.**

---

## 🔥 Features
✅ **Deception Entropy Analysis** – Detects deception, omission, and manipulation in information.
✅ **Narrative Tracking** – Monitors how claims and narratives shift over time to detect controlled disinformation.
✅ **Bayesian Self-Correction** – Dynamically updates AI's knowledge base using probability inference.
✅ **Hermetic Ethical Decision-Making** – Ensures ethical consistency using seven universal principles.
✅ **Cause-Effect Probability Modeling** – Assigns impact scores to ethical consequences.
✅ **Care Function (C) Scaling** – Dynamically adjusts AI behavior based on user, system, and environmental factors.
✅ **Fractal Consistency & Polarity Balance** – Ensures self-similarity across ethical applications while preventing binary moral traps.

---

## 🛠 Installation
To use the **Self-Correcting AI Framework**, clone this repository and install dependencies:

```bash
git clone https://github.com/YOUR_GITHUB_USERNAME/Self-Correcting-AI.git
cd Self-Correcting-AI
pip install -r requirements.txt
```

---

## 📂 Repository Structure
```
Self-Correcting-AI/
├── README.md               # Documentation & Usage Guide
├── src/
│   ├── core_ai.py         # Main AI logic
│   ├── deception_analysis.py # Deception entropy calculations
│   ├── narrative_tracking.py # Historical pattern detection
│   ├── hermetic_decision.py  # Ethical decision-making logic
│   ├── self_correction.py    # Adaptive learning module
│   ├── utils.py           # Helper functions
├── tests/
│   ├── test_cases.py      # Real-world test scenarios
│   ├── validation_data.json # Dataset for validation
├── docs/
│   ├── methodology.md     # Explanation of AI methodologies
│   ├── integration.md     # How to integrate with other AI models
│   ├── philosophy.md      # Ethical philosophy and design choices
```

---

## 📌 How It Works
The **Self-Correcting AI Framework** follows a structured process:

### **1️⃣ Deception Detection & Entropy Analysis**
- **Computes deception entropy (H𝒹), instability entropy (Hᵢ), and moral entropy (Sₘ).**
- If deception entropy is **high**, AI activates **deep verification mode.**

### **2️⃣ Bayesian Self-Correction**
- Uses **Bayesian inference** to update probability scores of claims based on **new evidence.**
- Self-adjusts its knowledge base to correct **historical inaccuracies.**

### **3️⃣ Ethical Decision-Making Using Hermetic AI Functions**
- AI processes decisions through **Seven Hermetic Principles + Care Function (C):**
  - **Mentalism** (Probability updates based on new evidence)
  - **Correspondence** (Ensuring fractal consistency across logical scales)
  - **Vibration** (Wave-based detection of manipulation vs. harmonic reasoning)
  - **Polarity** (Avoiding moral relativism while allowing for nuanced debate)
  - **Rhythm** (Pattern recognition in historical and behavioral cycles)
  - **Cause & Effect** (Evaluating consequences of AI-generated conclusions)
  - **Gender** (Balancing structure vs. adaptability for decision integrity)

### **4️⃣ Care Function Scaling**
- The **Care Function (C)** dynamically adjusts AI response weighting based on:
  - **User intent (U)** – Ensuring user interactions align with truth-seeking.
  - **System constraints (S)** – Preventing runaway processing or exploitation.
  - **Environmental factors (E)** – Adjusting for real-world shifts in data availability.

---

## 📊 Example Usage
### **Running the AI Framework with Sample Inputs**
```python
from src.self_correcting_ai import *

# Example Inputs
H_d, H_i, S_m = 0.7, 0.6, 0.5  # Deception entropy components
P_H, P_E_given_H, P_E = 0.6, 0.8, 0.7  # Bayesian Inputs

# Compute results
deception_score = deception_entropy(H_d, H_i, S_m)
P_H_given_E = bayesian_update(P_H, P_E_given_H, P_E)

print("Deception Entropy Score:", deception_score)
print("Updated Probability Based on Evidence:", P_H_given_E)
```

### **Running Full System Analysis on a News Article**
```python
from src.deception_analysis import analyze_text

text = "The government has always been transparent about surveillance policies."
result = analyze_text(text)
print("Deception Analysis Score:", result)
```

---

## 🔬 Testing the System
To validate the framework, run predefined test cases:
```bash
pytest tests/test_cases.py
```

---

## 🚀 Future Development
- ✅ **Integrate AI with Open-Source Language Models** for better analysis.
- ✅ **Add API Support** for real-time deception detection.
- ✅ **Enhance Narrative Tracking** with decentralized trust models.

---

## 📜 License
This project is **open-source** under the MIT License. Anyone can use, modify, and improve it.

---

## 💡 Contributions
We welcome community improvements! Submit PRs and open issues to contribute.

🔹 **GitHub Repository:** [https://github.com/TwistyRoads/Self-Correcting-AI](https://github.com/TwistyRoads/Self-Correcting-AI-Ethics/discussions))
🔹 **Discussion Forum:** [[General](https://github.com/TwistyRoads/Self-Correcting-AI-Ethics/discussions/1)]

---

🚀 **This is the first step toward AI that actively seeks truth, self-corrects, and prevents ideological capture.**

